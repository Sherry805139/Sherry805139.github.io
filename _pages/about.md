---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am interested in **Multimodal Large Language Models**, with a primary focus on **Parameter-Efficient Fine-Tuning (PEFT)**. My current research centers on developing scalable algorithms for the **retrieval and composition of modular expert modules** (e.g., LoRAs), aiming to enable efficient knowledge integration and adaptation across diverse modalities. Building on this modular foundation, I am also exploring the potential for **Self-evolving Agents** that can autonomously refine their capabilities through continuous interaction and feedback.


- **National Scholarship** (2024, 2025)
- **Gold Medal** — Zhejiang International College Students Innovation Competition (AI Track), 2025
- Research intern (Aug 2025 – Present): privacy-preserving LoRA hub for GUI agents (FedMABench), including multimodal retrieval weighting + DP fusion
- AI Product Manager Intern @ Meituan Search (Jul 2025 – Sep 2025)
